{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is a project notebook to predict the scores of students using a few features about the school. \n",
    "\n",
    "Data source: https://www.kaggle.com/kwadwoofosu/predict-test-scores-of-students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "# import sklearn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV as DataFrame\n",
    "df = pd.read_csv(\"test_scores.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DataFrame information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the summary and description for all columns\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are not required for now\n",
    "df = df.drop(['student_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode lunch\n",
    "lunch_le = LabelEncoder()\n",
    "\n",
    "df['lunch'] = lunch_le.fit_transform(df['lunch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode gender\n",
    "gender_le = LabelEncoder()\n",
    "\n",
    "df['gender'] = gender_le.fit_transform(df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode school setting\n",
    "school_setting_le = LabelEncoder()\n",
    "\n",
    "df['school_setting'] = school_setting_le.fit_transform(df['school_setting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode school type\n",
    "school_type_le = LabelEncoder()\n",
    "\n",
    "df['school_type'] = school_type_le.fit_transform(df['school_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode teaching method\n",
    "teaching_method_le = LabelEncoder()\n",
    "\n",
    "df['teaching_method'] = teaching_method_le.fit_transform(df['teaching_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a quick look at the score distribution\n",
    "plt.hist(df['n_student'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns that are only numbers\n",
    "df_temp = df.select_dtypes('number')\n",
    "\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the distribution of the difference in scores between pretest and posttest\n",
    "plt.hist(df_temp['posttest'] - df_temp['pretest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(df_temp['pretest'] + 12, df_temp['posttest'])))\n",
    "plt.scatter(df_temp['pretest'] + 12, df_temp['posttest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_temp.drop(['pretest', 'posttest'], axis=1)\n",
    "X = df_temp.drop(['posttest'], axis=1)\n",
    "y = df_temp['posttest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_temp['posttest'] - df_temp['pretest']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y_test, X_test['pretest'] + 12)))\n",
    "plt.scatter(X_test['pretest'] + 12, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, lr_pred)))\n",
    "\n",
    "plt.scatter(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train)\n",
    "tree_pred = tree.predict(X_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, tree_pred)))\n",
    "\n",
    "plt.scatter(y_test, tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()\n",
    "forest.fit(X_train, y_train)\n",
    "forest_pred = forest.predict(X_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, forest_pred)))\n",
    "\n",
    "plt.scatter(y_test, forest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of the first row of X_test\n",
    "forest_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the residuals\n",
    "plt.scatter(y_test.index, y_test - forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the model as a .joblib file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the model as a .joblib file\n",
    "dump(forest, 'forest_v1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the .joblib file\n",
    "loaded_forest = load('forest_v1.joblib')\n",
    "loaded_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a quick look at the test dataframe\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random row\n",
    "X_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corresponding y test data\n",
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the loaded model\n",
    "loaded_forest.predict(X_test.iloc[[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
